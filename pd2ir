#!/usr/bin/env python3
"""
pd2ir - Convert Pure Data patches to IR and DSL formats

Usage:
    pd2ir <file.pd>              # Convert once (IR + DSL)
    pd2ir --validate <file.pd>   # Validate syntax only (fast)
    pd2ir --no-dsl <file.pd>     # Generate IR only, skip DSL
    pd2ir --watch <file.pd>      # Watch for changes and auto-convert
    pd2ir --watch <directory>    # Watch all .pd files in directory
"""

import sys
import os
import time
import argparse
from pathlib import Path

# Add pdpy to path if running from repo
script_dir = Path(__file__).parent.resolve()
if (script_dir / 'pdpy_lib').exists():
    sys.path.insert(0, str(script_dir))

from pdpy_lib.patching.pdpy import PdPy
from pdpy_lib.utilities.utils import loadPdFile, parsePdFileLines


def convert_file(pd_path: Path, quiet: bool = False, validate_only: bool = False, no_dsl: bool = False) -> bool:
    """Convert a .pd file to IR JSON and DSL formats."""
    try:
        # Load and parse
        raw = loadPdFile(str(pd_path))
        pd_lines = parsePdFileLines(raw)
        pdpy = PdPy(name=pd_path.stem, pd_lines=pd_lines)

        if validate_only:
            # Just parse to verify syntax
            if not quiet:
                print(f"[valid] {pd_path.name}")
            return True

        # Output paths
        base = pd_path.with_suffix('')
        json_path = pd_path.parent / f"{pd_path.name}-ir.json"
        dsl_path = pd_path.parent / f"{pd_path.name}-ir.dsl"

        # Generate IR
        ir = pdpy.to_ir(patch_path=str(pd_path))

        # Write JSON
        with open(json_path, 'w') as f:
            f.write(ir.to_json())

        # Write DSL
        if not no_dsl:
            from pdpy_lib.ir.dsl import ir_to_dsl, DSLMode
            dsl_content = ir_to_dsl(ir, DSLMode.COMPACT)
            with open(dsl_path, 'w') as f:
                f.write(dsl_content)

        if not quiet:
            print(f"[ok] {pd_path.name}")
            print(f"     -> {json_path.name}")
            if not no_dsl:
                print(f"     -> {dsl_path.name}")

        return True

    except Exception as e:
        print(f"[error] {pd_path.name}: {e}", file=sys.stderr)
        return False


def get_mtime(path: Path) -> float:
    """Get file modification time, or 0 if doesn't exist."""
    try:
        return path.stat().st_mtime
    except OSError:
        return 0


def watch_files(paths: list[Path], interval: float = 1.0):
    """Watch files for changes and reconvert."""
    # Track modification times
    mtimes = {p: get_mtime(p) for p in paths}

    print(f"Watching {len(paths)} file(s) for changes... (Ctrl+C to stop)\n")

    # Initial conversion
    for p in paths:
        convert_file(p)

    print()

    try:
        while True:
            time.sleep(interval)

            for p in paths:
                new_mtime = get_mtime(p)
                if new_mtime > mtimes[p]:
                    mtimes[p] = new_mtime
                    print(f"\n[changed] {p.name}")
                    convert_file(p)
                    print()

    except KeyboardInterrupt:
        print("\nStopped watching.")


def find_pd_files(directory: Path) -> list[Path]:
    """Find all .pd files in a directory (non-recursive)."""
    return sorted(directory.glob("*.pd"))


def main():
    parser = argparse.ArgumentParser(
        description="Convert Pure Data patches to IR and DSL formats",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
    pd2ir main.pd                    # Convert single file
    pd2ir --validate main.pd         # Validate syntax only (fast)
    pd2ir --no-dsl main.pd           # Generate IR JSON only (no DSL)
    pd2ir --watch main.pd            # Watch single file
    pd2ir --watch .                  # Watch all .pd files in current dir
    pd2ir *.pd                       # Convert multiple files
        """
    )
    parser.add_argument('paths', nargs='+', help='Path(s) to .pd file(s) or directory')
    parser.add_argument('-w', '--watch', action='store_true', help='Watch for changes')
    parser.add_argument('-q', '--quiet', action='store_true', help='Quiet output')
    parser.add_argument('-v', '--validate', action='store_true', help='Validate only, no file output')
    parser.add_argument('--no-dsl', action='store_true', help='Skip DSL generation (faster)')

    args = parser.parse_args()

    # Collect all .pd files to process
    pd_files = []
    for p in args.paths:
        path = Path(p).resolve()
        if path.is_dir():
            found = find_pd_files(path)
            if not found:
                print(f"No .pd files found in {path}", file=sys.stderr)
            pd_files.extend(found)
        elif path.suffix == '.pd':
            if path.exists():
                pd_files.append(path)
            else:
                print(f"File not found: {path}", file=sys.stderr)
        else:
            print(f"Not a .pd file: {path}", file=sys.stderr)

    if not pd_files:
        print("No files to process.", file=sys.stderr)
        sys.exit(1)

    # Remove duplicates while preserving order
    seen = set()
    pd_files = [p for p in pd_files if not (p in seen or seen.add(p))]

    if args.watch:
        watch_files(pd_files)
    else:
        # One-time conversion
        success = 0
        for p in pd_files:
            if convert_file(p, quiet=args.quiet, validate_only=args.validate, no_dsl=args.no_dsl):
                success += 1

        if len(pd_files) > 1:
            print(f"\nConverted {success}/{len(pd_files)} files")

        sys.exit(0 if success == len(pd_files) else 1)


if __name__ == '__main__':
    main()
